
<!DOCTYPE html>
<html>
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-50WY0T5K5Q"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-50WY0T5K5Q');
    </script>
    <!-- Adapted from Dave Epstein's BlogGAN webpage template: https://dave.ml/blobgan/ -->
    <title>Gabriel Sarch</title>
    <!-- <link rel="icon" type="image/x-icon" href="https://brain-dissection.github.io/images/logo_ai.png"> -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <link rel="stylesheet" href="css/style.css">
    <style>
      /* html,body,h1,h2,h3,h4,h5,h6 {font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;}
       */
       :root {
    /* Tailwind-like Inter stack */
    --font-sans: "Inter", ui-sans-serif, system-ui, -apple-system,
                 BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue",
                 Arial, "Noto Sans", sans-serif, "Apple Color Emoji",
                 "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
  }
  html, body, h1, h2, h3, h4, h5, h6 {
    font-family: var(--font-sans);
  }
  /* Optional: better rendering */
  html { -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; }
  body { font-optical-sizing: auto; line-height: 1.5; }
      .cite { padding:0px; background:#ffffff; font-size:18px}
      .card {border: 1px solid #ccc}
      img { margin-bottom:-6px;}
      p { font-size:18px;}
    </style>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="https://fonts.sandbox.google.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <meta name="theme-color" content="#f5ece5">
    <link rel="mask-icon" href="safari-pinned-tab.svg" color="#276FBF">
    <meta name="msapplication-TileColor" content="#276FBF">
    <link rel="stylesheet" href="/fonts.css">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <style>
    
    .btn {
    color: rgb(59, 123, 160);
    background-color: #8bb2ff1e
    }

    body {
        padding-bottom: 50px;
    }

    .btn-primary {
    color: #1b212b;
    background-color: #a7c4fff1
    }

    .paperimage {
	  padding-right: 1.5%;
      width: 32%;
	  min-width: 240px;
	  max-width: 340px;
      vertical-align: middle;
      }

    .papertext {
    width: auto;
    vertical-align: middle;
    }

    .papertable {
	  width:100%;
	  border:0px;
	  border-spacing:0px;
	  border-collapse:separate;
	  margin-right:auto;
	  margin-left:auto;
	  margin-bottom:2em;
      }

    .papercontainer {
    min-height: 10em;
    display: table-cell;
    vertical-align: middle
    }
    .paper {; }
    .padright {padding-right:1em; }
    .padimg { padding-bottom:1em; padding-top: 1em; width: 100%}
    .nopadimg {
        width: 100%;
        aspect-ratio: 16 / 9;
        height: auto;
        display: block;
        object-fit: cover;
        border-radius: 16px;
        background: #f0f2f7;
    }
    .nopadimg--contain {
        object-fit: contain;
    }
    .nopadimg--bottom {
        object-position: center bottom;
    }
    .icon {
    float: left;
    width: 40px;
    height: 40px;
    margin-right: 5px;
    }
    .email {
    padding-top: 10px;
    float: right;
    height: 0;
    opacity: 0;
    transition: opacity 0.7s;
    }

    .gabe-background {background-color:#8bb2ff59;color: #434849;}

    .btn.round {
        border-radius: 24px;
    }
    .btn-primary.round {
        border-radius: 24px;
    }
    
    a, a:link, a:visited {
    color: rgb(59, 123, 160);
    text-decoration: none;
    }

    .tab {
    margin-left: 2.5em
    }

</style>

<style>
    .project-links {
        max-width: 600px;
        display: flex;
        gap: 20px;
        flex-wrap: wrap;
        margin-left:22px;
    }
</style>

<!-- Paper button -->
<style>
    .btn-paper {
        width: 90px;
        height: 35px;
        cursor: pointer;
        border-radius: 15px;
        background: transparent;
        /* border: 2px solid #91C9FF; */
        outline: none;
        transition: 1s ease-in-out;
        text-decoration: none;
        align-items: center;
        display: flex;
        text-align: center;
        font-weight: 500;
        color: black;
    }
    .btn-paper:link {
        color: black;
    }
    .btn-paper:visited {
        color: black;
    }
    .btn-paper:active {
        color: black;
    }

    .btn-paper:hover {
        transition: 0.75s ease-in-out;
        background: #8bb2ff1e;
        text-decoration: none;
        font-weight: 500;
        color: black;
    }

    .vertical-center-paper {
        height: 80%;
        position: relative;
        /* top: 0px;
            right: 0;
            float: left; */
        /* padding-right: 1px;
        padding-left: 6px;
        padding-bottom: 4px; */
        padding-right: 8px;
        padding-left: 10px;
        padding-bottom: 4px;
    }

    .btn-paper-helperx {
        width: 120px;
        height: 35px;
        cursor: pointer;
        border-radius: 15px;
        background: transparent;
        /* border: 2px solid #91C9FF; */
        outline: none;
        transition: 1s ease-in-out;
        text-decoration: none;
        align-items: center;
        display: flex;
        text-align: center;
        font-weight: 500;
        color: black;
    }
    .btn-paper-helperx:link {
        color: black;
    }
    .btn-paper-helperx:visited {
        color: black;
    }
    .btn-paper-helperx:active {
        color: black;
    }

    .btn-paper-helperx:hover {
        transition: 0.75s ease-in-out;
        background: #8bb2ff1e;
        text-decoration: none;
        font-weight: 500;
        color: black;
    }
</style>

<!-- Code button -->
<style>
    .btn-code {
        width: 80px;
        height: 35px;
        cursor: pointer;
        border-radius: 15px;
        background: transparent;
        /* border: 2px solid #91C9FF; */
        outline: none;
        transition: 1s ease-in-out;
        text-decoration: none;
        align-items: center;
        display: flex;
        text-align: center;
        font-weight: 500;
        color: black;
    }
    .btn-code:link {
        color: black;
    }
    .btn-code:visited {
        color: black;
    }
    .btn-code:active {
        color: black;
    }

    .btn-code:hover {
        transition: 0.75s ease-in-out;
        background: #8bb2ff1e;
        text-decoration: none;
        font-weight: 500;
    }

    .vertical-center-code {
        height: 60%;
        position: relative;
        /* top: 0px;
            left: 0px;
            float: left; */
        padding-right: 8px;
        padding-left: 10px;
        padding-bottom: 4px;
    }
</style>

<!-- Citation button -->
<style>
    .btn-project-page {
        width: 130px;
        height: 35px;
        cursor: pointer;
        border-radius: 15px;
        background: transparent;
        /* border: 2px solid #91C9FF; */
        outline: none;
        transition: 1s ease-in-out;
        text-decoration: none;
        align-items: center;
        display: flex;
        text-align: center;
        font-weight: 500;
        color: black;
    }

    .btn-project-page:link {
        color: black;
    }
    .btn-project-page:visited {
        color: black;
    }
    .btn-project-page:active {
        color: black;
    }

    .btn-project-page:hover {
        transition: 0.75s ease-in-out;
        background: #8bb2ff1e;
        text-decoration: none;
        font-weight: 500;
        color: black;
    }

    .vertical-center-pp {
        height: 70%;
        position: relative;
        /* top: 0px;
            right: 0;
            float: left; */
        padding-right: 6px;
        padding-left: 6px;
        padding-bottom: 3px;
    }
    .research-blurb { font-size: 18px; line-height: 1.7; margin: 32px 0; }
    .research-blurb p { margin: 0 0 16px; }
    .research-blurb__lead { font-weight: 500; letter-spacing: 0.01em; }
    .research-blurb__list { list-style: disc; margin: 0; padding-left: 24px; display: grid; gap: 12px; }
    .research-blurb__topic { font-weight: 600; }
    .news { margin: 48px 0; padding: 32px 36px; background: #fbfbfc; border: 1px solid #e5e8ef; border-radius: 18px; box-shadow: 0 10px 24px -18px rgba(29, 36, 53, 0.25); }
    .news__header { display: flex; align-items: center; justify-content: flex-start; gap: 16px; margin-bottom: 24px; }
    .news__header h1 { margin: 0; font-size: 28px; }
    .news__list { display: grid; gap: 18px; margin: 0; padding: 0; max-height: 420px; overflow-y: auto; padding-right: 12px; }
    .news__item { display: grid; grid-template-columns: 130px 1fr; gap: 20px; padding-left: 12px; border-left: 3px solid #d2d7e3; }
    .news__date { font-size: 15px; font-weight: 600; letter-spacing: 0.02em; color: #4a4a4a; }
    .news__text { margin: 0; font-size: 17px; line-height: 1.6; }
    .news__text a { color: inherit; border-bottom: 1px solid rgba(110, 120, 140, 0.35); }
    .news__text a:hover { border-color: rgba(110, 120, 140, 0.65); }
    .publications-header { margin-bottom: 24px; }
    @media (max-width: 640px) {
        .news { padding: 24px; }
        .news__list { max-height: 60vh; padding-right: 0; }
        .news__item { grid-template-columns: 1fr; border-left: none; border-top: 3px solid #c6d9ff; padding: 18px 0 0; }
    }
</style>

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:opsz,wght@14..32,300..900&display=swap" rel="stylesheet">

  </head>  
  <body class="w3-white">
    <!-- <h5> <a href="/" style="text-decoration: none; color:inherit;">Gabriel Sarch</a> </h5>  -->
    <br><br>
    <div class="w3-content w3-margin-top w3-margin-bottom" style="max-width:960px;">
        <div class="w3-row-padding w3-content" style="max-width:960px;">
        <div class="w3-row w3-white">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr style="padding:0px">
            <td style="padding-right:2.5%;width:70%;vertical-align:middle">
                <h1>Hi, I'm Gabe Sarch</h1>
                <p>
                  I'm a Postdoctoral Research Fellow in 
                  <a href="https://pli.princeton.edu/" style="text-decoration: none;">Princeton Language and Intelligence (PLI)</a> at Princeton University. I completed my Ph.D. at Carnegie Mellon University in Machine Learning (<a href="https://ml.cmu.edu/about/" style="text-decoration: none;">MLD</a> & <a href="https://www.cmu.edu/ni/index.html" style="text-decoration: none;">NI</a>) in 2025. I was fortunate to be advised by Drs. <a href="https://www.cs.cmu.edu/~katef/" style="text-decoration: none;">Katerina Fragkiadaki</a> and <a href="https://sites.google.com/andrew.cmu.edu/tarrlab/people/michael-j-tarr" style="text-decoration: none;">Mike Tarr</a>.
                </p>
                  <p>
                  Previously, I held research positions at 
                  <a href="https://www.microsoft.com/en-us/research/group/future-experiences/#:~:text=The%20Future%20Experiences%20(FX)%20research,and%20observational%20study%20of%20human" style="text-decoration: none;">Microsoft Research</a> 
                  and <a href="https://yutori.com/" style="text-decoration: none;">Yutori AI</a>, and received the National Science Foundation Graduate Research Fellowship.
                  
                </p>
            </td>
            <td style="padding-left:0.5%;width:40%;max-width:30%">
            <img style="width:100%;max-width:100%;border-radius: 25px;" alt="profile photo" src="images/main_photo.jpg">
            </td>
            </tr>
        </table>
        <div>
            <a href="https://twitter.com/GabrielSarch"><input type="image" src="images/twitter_grey.png" width="40" height="40"
                    name="saveForm" class="btTxt submit" style="left: 10px; top: 10px;" id="saveForm" /></a>
            <a href="https://github.com/Gabesarch"> &thinsp; <input type="image" src="images/github.png" width="40" height="40"
                    name="saveForm" class="btTxt submit" style="left: 10px; top: 10px;" id="saveForm" /></a>
            <a href="https://scholar.google.com/citations?user=9rYWAhsAAAAJ&hl=en"> &thinsp; <input type="image"
                    src="images/googlescholar_grey.png" width="40" height="40" name="saveForm" class="btTxt submit"
                    style="left: 10px; top: 10px;" id="saveForm" /></a>
            <a href="gsarch_CV.pdf"> &thinsp; <input type="image" src="images/CV.png" width="40" height="40" name="saveForm"
                    class="btTxt submit" style="left: 10px; top: 10px;" id="saveForm" /></a>
            <a href="mailto:gs1693@princeton.edu"> &thinsp; <input type="image" src="images/email_grey.png" width="40" height="40"
                    name="saveForm" class="btTxt submit" style="left: 10px; top: 10px;" id="saveForm" /></a>
        </div>
        </div>
        </div>
        <br>
        <section id="research-blurb" class="research-blurb">
            <!-- My research focus is on learning methods for general multimodal reasoning and decision-making. This comes in two parts: 1) understanding how active intelligence works in humans and animals, and 2) building generalist multimodal agents that learn to reason and act in dynamic, multimodal environments. -->
            <p>
                Human learning and reasoning are active processes. We move, probe, and explore to make sense of dynamic, multimodal environments. I aim to build agents that learn strategies generalizable to complex, novel tasks.
            </p>
            <p>
                This comes in two parts: (i) reverse-engineering agentic intelligence in humans and animals, and (ii) developing algorithms for generalist agents that learn to reason and act from interactive, multimodal experience.
            </p>
            <p class="research-blurb__lead">
                Some focus areas towards this goal:
            </p>
            <ul class="research-blurb__list">
                <li><span class="research-blurb__topic">Grounded Visual Reasoning.</span> <a href="https://arxiv.org/abs/2505.23678" style="text-decoration: none;">ViGoRL</a>, <a href="https://arxiv.org/abs/2505.01578" style="text-decoration: none;">MICA</a></li>
                <li><span class="research-blurb__topic">Memory-Augmented Agents.</span> <a href="https://arxiv.org/abs/2406.14596" style="text-decoration: none;">ICAL</a>, <a href="https://arxiv.org/abs/2310.15127" style="text-decoration: none;">HELPER</a>, <a href="https://arxiv.org/abs/2207.10761" style="text-decoration: none;">TIDEE</a></li>
                <li><span class="research-blurb__topic">Characterizing Natural Intelligence.</span> <a href="https://www.biorxiv.org/content/10.1101/2023.05.29.542635v2" style="text-decoration: none;">Brain Dissection</a>, <a href="http://127.0.0.1:3000/images/CCN_2023.pdf" style="text-decoration: none;">View Prediction Models</a>, <a href="https://www.nature.com/articles/s41467-023-38564-9" style="text-decoration: none;">Beyond Fixation</a></li>
            </ul>
        </section>
        <section class="news" aria-labelledby="news-heading">
            <div class="news__header">
                <h1 id="news-heading">News</h1>
            </div>
            <div class="news__list">
                <article class="news__item">
                    <time class="news__date" datetime="2025-05">Sept 2025</time>
                    <p class="news__text">Gave a talk on grounded reinforcement learning for visual reasoning at the <a href="https://pli.princeton.edu/events/2025/grounded-reinforcement-learning-visual-reasoning" style="text-decoration: none;">PLI Seminar</a>.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2025-05">Sept 2025</time>
                    <p class="news__text">Started a Postdoctoral Research Fellow position with <a href="https://pli.princeton.edu/" style="text-decoration: none;">Princeton Language and Intelligence (PLI)</a> at Princeton University.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2025">Sept 2025</time>
                    <p class="news__text">Serving on the AISTATS 2025 Program Committee.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2025-08">Aug 2025</time>
                    <p class="news__text">Completed my Ph.D. in Machine Learning and Neural Computation at Carnegie Mellon University.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2025">Aug 2025</time>
                    <p class="news__text">“Out of Sight, Not Out of Context? Egocentric Spatial Reasoning in VLMs Across Disjoint Frames” appearing at EMNLP 2025.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2025-05">May 2025</time>
                    <p class="news__text">Released the <a href="https://arxiv.org/abs/2505.23678" style="text-decoration: none;">ViGoRL</a> preprint on grounded reinforcement learning for multimodal reasoning. Code, models, datasets are all open-source <a href="https://github.com/Gabesarch/ViGoRL" style="text-decoration: none;">here</a>.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2025">March 2025</time>
                    <p class="news__text">“Reanimating Images using Neural Representations of Dynamic Stimuli” accepted as an oral presentation at CVPR 2025.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2025">March 2025</time>
                    <p class="news__text">“Multimodal Interactive Contextualized Real World Task Assistance from a Single Demonstration” published in ACL Findings 2025.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2024-12">Sept 2024</time>
                    <p class="news__text">“VLM Agents Generate Their Own Memories” received a NeurIPS 2024 Spotlight recognition.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2024-08">Aug 2024</time>
                    <p class="news__text">Joined Yutori as Technical Staff (AI) to build multimodal model infrastructure through Dec 2024.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2024-06">June 2024</time>
                    <p class="news__text">“Towards Unified 2D-3D Visual Scene Understanding Foundation Models” spotlighted at CVPR 2024.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2024-05">May 2024</time>
                    <p class="news__text">Started a research internship at Microsoft Research working on the MICA real-time assistance system.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2024">May 2024</time>
                    <p class="news__text">Gave an invited talk on task planning with LLMs at Carnegie Mellon’s Search-based Planning Laboratory.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2024">May 2024</time>
                    <p class="news__text">Presented “Open-Ended Instructable Embodied Agents” at CMU Catalyst’s LLM Agents Seminar.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2023">May 2023</time>
                    <p class="news__text">Completed an M.S. in Machine Learning Research at Carnegie Mellon University.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2024">Jan 2024</time>
                    <p class="news__text">“HELPER-X: A Unified Instructable Embodied Agent” presented at the ICLR 2024 LLM Agents Workshop.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2023">Oct 2023</time>
                    <p class="news__text">Won the Embodied AI Workshop Rearrangement Challenge at CVPR 2023.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2023">Aug 2023</time>
                    <p class="news__text">“Open-Ended Instructable Embodied Agents with Memory-Augmented LLMs” published in EMNLP Findings 2023.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2023">Aug 2023</time>
                    <p class="news__text">“Brain Dissection: fMRI-trained Networks Reveal Spatial Selectivity” accepted at NeurIPS 2023.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2023">March 2023</time>
                    <p class="news__text">“3D View Prediction Models of the Dorsal Visual Stream” presented at CCN 2023.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2023">March 2023</time>
                    <p class="news__text">“Beyond Fixation: detailed characterization of neural selectivity in free-viewing primates” published in Nature Communications 2023.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2023">Jan 2023</time>
                    <p class="news__text">Delivered the brAIn Seminar talk “Spatial Processing During Natural Scene Viewing.”</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2023">Feb 2023</time>
                    <p class="news__text">Gave an invited lecture in CMU’s Biologically Intelligent Exploration course on evidence-based decision making.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2022">Feb 2022</time>
                    <p class="news__text">Runner-up in the Amazon Alexa Prize SimBot Embodied Dialogue Challenge.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2022">March 2022</time>
                    <p class="news__text">“TIDEE: Tidying Up Novel Rooms using Visuo-Semantic Common Sense Priors” accepted at ECCV 2022.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2021">June 2021</time>
                    <p class="news__text">“Move to See Better: Self-Improving Embodied Object Detection” accepted at BMVC 2021.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2020">May 2020</time>
                    <p class="news__text">Awarded the NSF Graduate Research Fellowship to support graduate research through 2025.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2020-08">Aug 2020</time>
                    <p class="news__text">Began Ph.D. studies in Machine Learning and Neural Computation at Carnegie Mellon University.</p>
                </article>
                <article class="news__item">
                    <time class="news__date" datetime="2019">2019</time>
                    <p class="news__text">Awarded the University of Rochester Center for Visual Science Research Fellowship.</p>
                </article>
            </div>
        </section>
      <div class="w3-row-padding">     
        <br><br>
	  <!-- <div class="w3-left-align">
        <br><br>
        <h2><strong>Embodied intelligence</strong></h2>
        <p>Animals utilize self-supervision, commonsense reasoning, and interaction to make sense of sensory inputs and perform embodied tasks without a significant amount of explicit labels or instructions. However, most state-of-the-art embodied systems require millions of human annotations and are not able to generalize their previously learned knowledge to accurately reason about novel inputs or tasks. My research focuses on embodied artificial agents that learn, act and reason by interactive and active means, drawing from psychological and neuroscientific literature when it is useful.</p>
        <br>
        <h2><strong>Computer vision models of the primate visual system</strong></h2>
        <p>Deep neural networks optimized for visual tasks have been shown to be good predictive models of neural responses in visual areas (e.g. fMRI, electrophysiology - see <a href="https://arxiv.org/abs/2001.07092" style="text-decoration: none;">here</a>). By modeling the representations and behaviors of primates with AI systems optimized for different tasks and inputs, we can better understand the neural representations underlying naturalistic stimuli processing in primates.</p>
	  </div> -->
      <br>
      <spacer type="horizontal" width="5" height="5"> </spacer>
      <br>
      <div class="w3-left-align publications-header">
	    <h1>Selected Publications</h1>
	  </div>
      <!-- <div class="example"> -->
        <div>
        <!-- <br> -->
        <table class="papertable">
            <tr style="padding:0px">
                <td class="paperimage">
                    <video src="images/tweet_graphic.m4v" class="nopadimg" autoplay muted loop></video>
                </td>
                <td class="papertext">
                    <div class="w3-left-align">
                        <!-- <h1 style="font-size:1.0vw; margin-left:25px;"> TIDEE: Novel Room Reorganization using Visuo-Semantic Common Sense Priors</h1> -->
                        <h4 style="margin-left:25px;">Grounded Reinforcement Learning for Visual Reasoning</h4>
                        <h5 style="margin-left:20px;"> <a href="https://www.gabesarch.me" style="text-decoration:none"
                                class="btn btn-light gabe-background round btn-sm" role="button"
                                style="background-color: #386dd8ea">GH Sarch</a>
                            &thinsp; <a href="https://www.linkedin.com/in/snigdha-saha/" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">S Saha</a>
                            &thinsp; <a href="https://www.linkedin.com/in/naitik-khandelwal-0a7758191/"
                                style="text-decoration:none" class="btn btn-light round btn-sm" role="button">N Khandelwal</a>
                            &thinsp; <a href="https://ayushjain1144.github.io/" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">A Jain</a>
                            &thinsp; <a href="https://sites.google.com/andrew.cmu.edu/tarrlab/people/michael-j-tarr" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">MJ Tarr</a>
                            &thinsp; <a href="https://aviralkumar2907.github.io/" style="text-decoration:none" class="btn btn-light round btn-sm"
                                role="button">A Kumar</a>
                            &thinsp; <a href="https://www.cs.cmu.edu/~katef/" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">K Fragkiadaki</a>
                            &thinsp; </h5>
                        <h5 style="margin-left:25px;"> NeurIPS 2025 </h5>
                    </div>
        
                    <div class="project-links">
                        <a href="https://arxiv.org/abs/2505.23678" target="_blank" class="btn-paper" role="button">
                            <img src="images/paper2.png" class="vertical-center-paper"> Paper
                        </a>
                        <a href="https://visually-grounded-rl.github.io/" target="_blank" class="btn-project-page" role="button">
                            <img src="images/project_page.png" class="vertical-center-pp"> Project Page
                        </a>
                        <a href="https://github.com/Gabesarch/grounded-rl" target="_blank" class="btn-code" role="button">
                            <img src="images/code.png" class="vertical-center-code"> Code
                        </a>
                    </div>
                    </div>
                </td>
            </tr>
        </table>
        <br>
        <hr>
        <table class="papertable">
            <tr style="padding:0px">
                <!-- <td class="paperimage">
                    <img src="images/Example_Track_Video.m4v" class="nopadimg">
                </td> -->
                <td class="paperimage">
                    <video src="images/Example_Track_Video.m4v" class="nopadimg" autoplay muted loop></video>
                </td>
                <td class="papertext">
                    <div class="w3-left-align">
                        <!-- <h1 style="font-size:1.0vw; margin-left:25px;"> TIDEE: Novel Room Reorganization using Visuo-Semantic Common Sense Priors</h1> -->
                        <h4 style="margin-left:25px;">Grounding Task Assistance with Multimodal Cues from a Single Demonstration</h4>
                        <h5 style="margin-left:20px;"> <a href="https://www.gabesarch.me" style="text-decoration:none"
                                class="btn btn-light gabe-background round btn-sm" role="button"
                                style="background-color: #386dd8ea">GH Sarch</a>
                            &thinsp; <a href="https://www.tkbala.com/" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">B Kumaravel</a>
                            &thinsp; <a href="https://sahithyaravi.github.io/"
                                style="text-decoration:none" class="btn btn-light round btn-sm" role="button">S Ravi</a>
                            &thinsp; <a href="https://vibhav-vineet.github.io/" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">V Vineet</a>
                            &thinsp; <a href="https://www.microsoft.com/en-us/research/people/awilson/" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">A Wilson</a>
                            &thinsp; </h5>
                        <h5 style="margin-left:25px;"> ACL 2025 <i style="font-weight: 300;">findings</i> </h5>
                    </div>
        
                    <div class="project-links">
                        <a href="https://arxiv.org/abs/2505.01578" target="_blank" class="btn-paper" role="button">
                            <img src="images/paper2.png" class="vertical-center-paper"> Paper
                        </a>
                    </div>
                    </div>
                </td>
            </tr>
        </table>
        <br>
        <hr>
        <table class="papertable">
            <tr style="padding:0px">
                <!-- <td class="paperimage">
                    <img src="images/shopping_296Agent-ezgif.com-video-to-gif-converter.gif" class="nopadimg">
                </td> -->
                <td class="paperimage">
                    <video src="images/learning_loop.mp4" class="nopadimg nopadimg--contain" autoplay muted loop></video>
                </td>
                <td class="papertext">
                    <div class="w3-left-align">
                        <!-- <h1 style="font-size:1.0vw; margin-left:25px;"> TIDEE: Novel Room Reorganization using Visuo-Semantic Common Sense Priors</h1> -->
                        <h4 style="margin-left:25px;">VLM Agents Generate Their Own Memories: Distilling Experience into Embodied Programs of Thought</h4>
                        <h5 style="margin-left:20px;"> <a href="https://www.gabesarch.me" style="text-decoration:none"
                                class="btn btn-light gabe-background round btn-sm" role="button"
                                style="background-color: #386dd8ea">GH Sarch</a>
                            &thinsp; <a href="https://www.linkedin.com/in/lawrencejang/" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">L Jang</a>
                            &thinsp; <a href="https://sites.google.com/andrew.cmu.edu/tarrlab/people/michael-j-tarr" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">MJ Tarr</a>
                            &thinsp; <a href="https://kennethmarino.com/" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">K Marino</a>
                            &thinsp; <a href="https://www.cs.cmu.edu/~wcohen/"
                                style="text-decoration:none" class="btn btn-light round btn-sm" role="button">W Cohen</a>
                            &thinsp; <a href="https://www.cs.cmu.edu/~katef/" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">K Fragkiadaki</a>
                            &thinsp; </h5>
                        <h5 style="margin-left:25px;"> NeurIPS 2024 Spotlight (Top 2%)</h5>
                    </div>
        
                    <div class="project-links">
                        <a href="https://arxiv.org/abs/2406.14596" target="_blank" class="btn-paper" role="button">
                            <img src="images/paper2.png" class="vertical-center-paper"> Paper
                        </a>
                        <a href="https://ical-learning.github.io/" target="_blank" class="btn-project-page" role="button">
                            <img src="images/project_page.png" class="vertical-center-pp"> Project Page
                        </a>
                        <a href="https://github.com/Gabesarch/ICAL" target="_blank" class="btn-code" role="button">
                            <img src="images/code.png" class="vertical-center-code"> Code
                        </a>
                    </div>
                    </div>
                </td>
            </tr>
        </table>
        <br>
        <hr>
        <table class="papertable">
            <tr style="padding:0px">
                <td class="paperimage">
                    <img src="images/PERSONALWEBSITE_GIF_HELPER.gif" class="nopadimg">
                </td>
                <td class="papertext">
                    <div class="w3-left-align">
                        <!-- <h1 style="font-size:1.0vw; margin-left:25px;"> TIDEE: Novel Room Reorganization using Visuo-Semantic Common Sense Priors</h1> -->
                        <h4 style="margin-left:25px;">Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models</h4>
                        <h5 style="margin-left:20px;"> <a href="https://www.gabesarch.me" style="text-decoration:none"
                                class="btn btn-light gabe-background round btn-sm" role="button"
                                style="background-color: #386dd8ea">GH Sarch</a> 
                                &thinsp; <a href="https://www.yuewu.ml/" style="text-decoration:none"
                                    class="btn btn-light round btn-sm" role="button">Y Wu</a>
                                &thinsp; <a
                                href="https://sites.google.com/andrew.cmu.edu/tarrlab/people/michael-j-tarr"
                                style="text-decoration:none" class="btn btn-light round btn-sm" role="button">MJ Tarr</a>
                            &thinsp; <a href="https://www.cs.cmu.edu/~katef/" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">K Fragkiadaki</a> 
                            &thinsp; </h5>
                        <h5 style="margin-left:25px;"> EMNLP 2023 <i style="font-weight: 300;">findings</i></h5>
                        <h6 style="margin-left:25px;">
                            🔥<font color="color:red;">[NEW!]</font> in ICLR 2024 Workshop on LLM Agents: HELPER-X achieves Few-Shot SoTA on 4 embodied AI benchmarks (ALFRED, TEACh,
                            DialFRED, and the Tidy Task) <em>using a single agent</em>, with just simple modifications to the original HELPER. 
                        </h6>
                    </div>
                    
                    <div class="project-links">
                        <a href="https://arxiv.org/abs/2310.15127" target="_blank" class="btn-paper"
                            role="button">
                            <img src="images/paper2.png" class="vertical-center-paper"> Paper
                        </a>
                        <a href="https://openreview.net/pdf?id=QfO0PdUq8c" target="_blank" class="btn-paper-helperx" role="button">
                            <img src="images/paper2.png" class="vertical-center-paper"> HELPER-X
                        </a>
                        <a href="https://helper-agent-llm.github.io/" target="_blank" class="btn-project-page" role="button">
                            <img src="images/project_page.png" class="vertical-center-pp"> Project Page
                        </a>
                        <a href="https://github.com/Gabesarch/HELPER" target="_blank" class="btn-code" role="button">
                            <img src="images/code.png" class="vertical-center-code"> Code
                        </a>
                    </div>
                    </div>
                </td>
            </tr>
        </table>
        <br>
        <hr>
        <table class="papertable">
            <tr style="padding:0px">
                <td class="paperimage">
                    <img src="images/braindissectteaser_cropped_fast.gif" class="nopadimg nopadimg--contain nopadimg--bottom">
                </td>
                <td class="papertext">
                    <div class="w3-left-align">
                        <!-- <h1 style="font-size:1.0vw; margin-left:25px;"> TIDEE: Novel Room Reorganization using Visuo-Semantic Common Sense Priors</h1> -->
                        <h4 style="margin-left:25px;">Brain Dissection: fMRI-trained Networks Reveal Spatial Selectivity in the Processing of Natural Images</h4>
                        <h5 style="margin-left:20px;"> <a href="https://www.gabesarch.me" style="text-decoration:none"
                                class="btn btn-light gabe-background round btn-sm" role="button"
                                style="background-color: #386dd8ea">GH Sarch</a> &thinsp; <a 
                                href="https://sites.google.com/andrew.cmu.edu/tarrlab/people/michael-j-tarr" style="text-decoration:none"
                                    class="btn btn-light round btn-sm" role="button">MJ Tarr</a> &thinsp; <a
                                href="https://www.cs.cmu.edu/~katef/" style="text-decoration:none" class="btn btn-light round btn-sm"
                                role="button">K Fragkiadaki*</a> &thinsp; <a href="https://www.cs.cmu.edu/~lwehbe/"
                                style="text-decoration:none" class="btn btn-light round btn-sm" role="button">L Wehbe*</a>
                            &thinsp; </h5>
                        <h7 style="margin-left:25px;"> *equal advising</h7>
                        <h5 style="margin-left:25px;"> NeurIPS 2023</h5>
                    </div>
                    <div class="project-links">
                        <a href="https://biorxiv.org/cgi/content/short/2023.05.29.542635" target="_blank" class="btn-paper" role="button">
                            <img src="images/paper2.png" class="vertical-center-paper"> Paper
                        </a>
                        <a href="https://brain-dissection.github.io/" target="_blank" class="btn-project-page" role="button">
                                    <img src="images/project_page.png" class="vertical-center-pp"> Project Page
                                </a>
                        <a href="https://github.com/Gabesarch/brain-dissection" target="_blank" class="btn-code" role="button">
                                    <img src="images/code.png" class="vertical-center-code"> Code
                                </a>
                    </div>
                    </div>
                </td>
            </tr>
        </table>
        <br>
        <hr>
        <table class="papertable">
            <tr style="padding:0px">
                <td class="paperimage">
                    <img src="images/view3ddorsal.jpg" class="nopadimg">
                </td>
                <td class="papertext">
                    <div class="w3-left-align">
                        <!-- <h1 style="font-size:1.0vw; margin-left:25px;"> TIDEE: Novel Room Reorganization using Visuo-Semantic Common Sense Priors</h1> -->
                        <h4 style="margin-left:25px;">3D View Prediction Models of the Dorsal Visual Stream</h4>
                        <h5 style="margin-left:20px;"> <a href="https://www.gabesarch.me" style="text-decoration:none"
                                class="btn btn-light gabe-background round btn-sm" role="button"
                                style="background-color: #386dd8ea">GH Sarch</a> &thinsp; <a
                                href="https://sfish0101.bitbucket.io/" style="text-decoration:none"
                                class="btn btn-light round btn-sm" role="button">HF Tung</a> &thinsp; <a
                                href="https://ariaywang.com/" style="text-decoration:none" class="btn btn-light round btn-sm"
                                role="button">A Wang</a> &thinsp; <a href="https://jacob-prince.github.io/"
                                style="text-decoration:none" class="btn btn-light round btn-sm" role="button">JS Prince</a>
                            &thinsp; <a href="https://sites.google.com/andrew.cmu.edu/tarrlab/people/michael-j-tarr"
                                style="text-decoration:none" class="btn btn-light round btn-sm" role="button">MJ Tarr</a></h5>
                        <h5 style="margin-left:25px;"> CCN 2023</h5>
                    </div>
                    <div class="project-links">
                        <a href="images/CCN_2023.pdf" target="_blank" class="btn-paper" role="button">
                            <img src="images/paper2.png" class="vertical-center-paper"> Paper
                        </a>
                        <!-- <a href="https://tidee-agent.github.io/" target="_blank" class="btn-project-page" role="button">
                            <img src="images/project_page.png" class="vertical-center-pp"> Project Page
                        </a> -->
                        <!-- <a href="https://github.com/Gabesarch/TIDEE" target="_blank" class="btn-code" role="button">
                            <img src="images/code.png" class="vertical-center-code"> Code
                        </a> -->
                    </div>
                    </div>
                </td>
            </tr>
        </table>
        <br>
        <hr>
    <table class="papertable">
        <tr style="padding:0px">
            <td class="paperimage">
                <img src="images/tidee_gif.gif" class="nopadimg">
            </td>
            <td class="papertext">
                <div class="w3-left-align">
                    <!-- <h1 style="font-size:1.0vw; margin-left:25px;"> TIDEE: Novel Room Reorganization using Visuo-Semantic Common Sense Priors</h1> -->
                    <h4 style="margin-left:25px;"> TIDEE: Tidying Up Novel Rooms using Visuo-Semantic Commonsense Priors
                    </h4>
                    <h5 style="margin-left:25px;color:rgb(0, 0, 0)"> 2023 CVPR Embodied AI Rearrangement Challenge winner
                    </h5>
                    <h5 style="margin-left:20px;"> <a href="https://www.gabesarch.me" style="text-decoration:none"
                            class="btn btn-light gabe-background round btn-sm" role="button"
                            style="background-color: #386dd8ea">GH Sarch</a> &thinsp; <a href="https://zfang399.github.io/"
                            style="text-decoration:none" class="btn btn-light round btn-sm" role="button">Z Fang</a>
                        &thinsp; <a href="https://cs.cmu.edu/~aharley/" style="text-decoration:none"
                            class="btn btn-light round btn-sm" role="button">AW Harley</a> &thinsp; <a
                            href="https://paulschydlo.com/" style="text-decoration:none" class="btn btn-light round btn-sm"
                            role="button">P Schydlo</a> &thinsp; <a
                            href="https://sites.google.com/andrew.cmu.edu/tarrlab/people/michael-j-tarr"
                            style="text-decoration:none" class="btn btn-light round btn-sm" role="button">MJ Tarr</a>
                        &thinsp; <a href="https://saurabhg.web.illinois.edu/" style="text-decoration:none"
                            class="btn btn-light round btn-sm" role="button">S Gupta</a> &thinsp; <a
                            href="https://www.cs.cmu.edu/~katef/" style="text-decoration:none"
                            class="btn btn-light round btn-sm" role="button">K Fragkiadaki</a></h5>
                    <h5 style="margin-left:25px;"> ECCV 2022</h5>
                </div>
                <div class="project-links">
                    <a href="https://arxiv.org/abs/2207.10761" target="_blank" class="btn-paper" role="button">
                        <img src="images/paper2.png" class="vertical-center-paper"> Paper
                    </a>
                    <a href="https://tidee-agent.github.io/" target="_blank" class="btn-project-page" role="button">
                        <img src="images/project_page.png" class="vertical-center-pp"> Project Page
                    </a>
                    <a href="https://github.com/Gabesarch/TIDEE" target="_blank" class="btn-code" role="button">
                        <img src="images/code.png" class="vertical-center-code"> Code
                    </a>
                    <a href="https://blog.ml.cmu.edu/2023/04/14/tidee-an-embodied-agent-that-tidies-up-novel-rooms-using-commonsense-priors/" target="_blank" class="btn-paper" role="button">
                        <img src="images/paper2.png" class="vertical-center-paper"> Blog
                    </a>
                </div>
                </div>
            </td>
        </tr>
    </table>
    <br>
    <hr>
        <table class="papertable">
        <tr style="padding:0px">
            <td class="paperimage">
            <img src="images/FreeView.png" class="nopadimg">
        </td>
        <td class="papertext">
        <div class="w3-left-align">
            <h4 style="margin-left:25px;"> Beyond Fixation: detailed characterization of neural selectivity in free-viewing primates</h4>
        <h5 style="margin-left:20px;"> <a href="https://jake.vision/" style="text-decoration:none" class="btn btn-light round btn-sm" role="button">JL Yates</a> &thinsp; <a href="https://www.linkedin.com/in/shannacoop/" style="text-decoration:none" class="btn btn-light round btn-sm" role="button">SH Coop</a> &thinsp; <a href="https://www.gabesarch.me" style="text-decoration:none" class="btn btn-light gabe-background round btn-sm" role="button" style="background-color: #386dd8ea">GH Sarch</a> &thinsp; <a style="text-decoration:none" class="btn btn-light round btn-sm" role="button">R Wu</a> &thinsp; <a href="https://neurotheory.umd.edu/" style="text-decoration:none" class="btn btn-light round btn-sm" role="button">D Butts</a> &thinsp; <a href="https://aplab.bcs.rochester.edu/" style="text-decoration:none" class="btn btn-light round btn-sm" role="button">M Rucci </a> &thinsp;<a href="https://marmolab.bcs.rochester.edu/" style="text-decoration:none" class="btn btn-light round btn-sm" role="button">Jude Mitchell</a> &thinsp;</h5>
            <h5 style="margin-left:25px;"> Nature Communications</h5>        
          </div>
            <div class="project-links">
                <a href="https://www.nature.com/articles/s41467-023-38564-9" target="_blank" class="btn-paper" role="button">
                    <img src="images/paper2.png" class="vertical-center-paper"> Paper
                </a>
            </div>
        </td>
    </tr>
    </table>
            <br>
            <hr>
        <table class="papertable">
            <tr style="padding:0px">
                <td class="paperimage">
                <img src="images/move_loop.gif" class="nopadimg">
            </td>
            <td class="papertext">
        <div class="w3-left-align">
            <h4 style="margin-left:25px;"> Move to See Better: Towards Self-Improving Embodied Object Detection</h4>
            <h5 style="margin-left:20px;"> <a href="https://www.gabesarch.me" style="text-decoration:none" class="btn btn-light gabe-background round btn-sm" role="button" style="background-color: #386dd8ea">GH Sarch*</a> &thinsp; <a href="https://zfang399.github.io/" style="text-decoration:none" class="btn btn-light round btn-sm" role="button">Z Fang*</a> &thinsp; <a href="https://ayushjain1144.github.io/" style="text-decoration:none" class="btn btn-light round btn-sm" role="button">A Jain*</a> &thinsp; <a href="https://www.cs.cmu.edu/~aharley/" style="text-decoration:none" class="btn btn-light round btn-sm" role="button">AW Harley </a> &thinsp; <a href="https://www.cs.cmu.edu/~katef/" style="text-decoration:none" class="btn btn-light round btn-sm" role="button">K Fragkiadaki</a></h5>
            <h7 style="margin-left:25px;"> *equal contribution</h7>
            <h5 style="margin-left:25px;"> BMVC 2021</h5>        
            </div>
                <div class="project-links">
                    <a href="https://arxiv.org/abs/2012.00057" target="_blank" class="btn-paper" role="button">
                        <img src="images/paper2.png" class="vertical-center-paper"> Paper
                    </a>
                    <a href="https://ayushjain1144.github.io/SeeingByMoving/" target="_blank" class="btn-project-page" role="button">
                        <img src="images/project_page.png" class="vertical-center-pp"> Project Page
                    </a>
                    <a href="https://github.com/ayushjain1144/SeeingByMoving" target="_blank" class="btn-code" role="button">
                        <img src="images/code.png" class="vertical-center-code"> Code
                    </a>
                </div>
            </td>
        </tr>
        </table>
            
            <br>
            <hr>
            <h5><a href="https://scholar.google.com/citations?user=9rYWAhsAAAAJ&hl=en">See all my publications</a></h5> 
            <br>
    </div>
	</div>
      </div>  
  </body>
</html>
